<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/avatar.png"/>
	<link rel="shortcut icon" href="/img/avatar.png">
	
			    <title>
    wuzhenren's blog
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="" />
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/sunset.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src=""></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo"></a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/Spring-Boot/">Spring Boot</a></li><li><a class="category-link" href="/categories/Spring-Boot/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/">工作日志</a></li><li><a class="category-link" href="/categories/leetcode/">leetcode</a></li><li><a class="category-link" href="/categories/ustc/">ustc</a></li><li><a class="category-link" href="/categories/ustc/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/">个人生活</a></li><li><a class="category-link" href="/categories/yisearch%E9%A1%B9%E7%9B%AE/">yisearch项目</a></li><li><a class="category-link" href="/categories/%E4%B8%AA%E4%BA%BA%E7%94%9F%E6%B4%BB/">个人生活</a></li><li><a class="category-link" href="/categories/%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%BF%97/">工作日志</a></li><li><a class="category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></li><li><a class="category-link" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE/">搜索系统项目</a></li><li><a class="category-link" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE/java/">java</a></li><li><a class="category-link" href="/categories/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/">踩坑日记</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="简历">
		                简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="团队">
		                团队
		            </a>
		        </li>
		        
		        <li>
		            <a href="/motto/" title="motto">
		                motto
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="标签">
		                标签
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/wzr1005" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="zhihu" href="https://www.zhihu.com/people/wu-zhen-ren" target="_blank" rel="noopener">
                            <i class="icon fa fa-zhihu"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://picjumbo.com/wp-content/uploads/mountains-sticking-out-of-inverse-in-a-beautiful-sunrise-light-2210x1243.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >5月20日</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332ag3b7yj214k0dutcm.jpg"></p>
<h1 id="www"><a href="#www" class="headerlink" title="www"></a>www</h1><p>Properties和Map都是以键值对的形式存储的，但是他们有什么区别吗？？<br>最大的区别就是 Properties可以直接导入IO流 读取IO流中的数据 并且能把自己的元素输出到IO流中。就是我们可以去写properties文件，进行读写。</p>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>kafka [] 命令后对topic增删改查 –config 引用配置文件</p>
<p>–list –create –describe 详情</p>
<p>分区内类似Hadoop，分块分割存储。分区从0开始，Leader为2  r<br>Replicas副本2 0 1。设计3个副本，分布于三台主机，</p>
<p>生产者消费者对Leader进行读写操作</p>
<p>分区数只能增加不能减少。不能通过命令行对方式增减副本。</p>
<p>开启消费服务之后，会增量的消费数据，加上from beginning 消费历史数据</p>
<p>Produce-&gt;Interceptors拦截器-&gt;Serializer序列化器-&gt;Pationer分区器，决定发送到哪个分区 以上过程在内存中完成默认32M。</p>
<p>只有数据累积到batch.size之后，sender才会发送数据，默认16k</p>
<p>linger.ms 数据如果迟迟未达到batch.size，sender等待linger.ms设置的时间</p>
<p>Request队列，由Kafka集群拉取到指定topic到指定分区，</p>
<p>拉取到时候，参考tcp的发送接收的缓冲区机制，允许5个或者若干个接收缓存，可以乱序，但接收缓存区必须接收完再进行下一批，否则重试等应答，发送的过程中进行集群的同步，消费一批，生产者删除一批。</p>
<p>Selector就是异步IO的方式，</p>
<p>同步、异步（情况较多）发送API，</p>
<p>回调函数，发送到队列，再返回发送结果。异步方法之后加上一个get()就行</p>
<p>表名字作为key，发到同一个表里面。</p>
<p>黏性分区，同一批数据尽量分在同一个分区，</p>
<h3 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h3><p> Leader收到数据，所有Follower都开始同步数据，但有一个Follower，因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢</p>
<p> Leader维护了一个动态的in-sync replica set(ISR),意为和Lead保持同步的Follower+Leader集合（leader： 0， isr： 0，1，2</p>
<p> 如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被<strong>踢出ISR</strong>，该时间阈值由<br> replica.lag.time.max.ms参数设定，默认30s。例如2超时，(leader:0, isr 0,1<br>)</p>
<p>这样就不用等长期联系不上或者已经故障等节点，以后就不接收他的消息了</p>
<p>数据完全可靠条件=ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</p>
<p>ACK=0，生产者发送过来的数据就不管了，可靠性差，效率高</p>
<p>ACK=1，生产者发送过来数据 Leader应答，可靠性中等，效率中等。</p>
<p>ACK=-1 可靠性最高，生产者发送过来数据Leader和ISR队列里面所有Follower应答，可靠性高，效率低</p>
<p>生产环境中，acks=0很少使用，acks=1，一般用于传输普通日志，允许丢个别数据</p>
<p>acks=-1，一般用于传输比较要紧的数据，不允许出错。</p>
<p>至少一次，ACK级别为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</p>
<p>最多一次，ACK级别设置为0<br>z<br>总结：</p>
<pre><code>ACK=-1可以保证数据不丢失，但不能保证数据不重复

ACK=0可以保证数据不重复，但是不能保证数据不丢失
</code></pre>
<p>生产环境中需要精确一次，对于一些重要的信息，</p>
<p>幂等性，就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一次，保证了不重复</p>
<p>精确一次=幂等性 + ACK = -1</p>
<p>重复数据的判断标准，具有&lt;PID,Partition,SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一次。其中PID时Kafka每次重启都会分配一个新的：partition表示分区号</p>
<p>Sequence Number是单调递增的</p>
<p>所以幂等性只能保证的是在单分区单会话内不重复</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务协调器，默认有50个分区，每个分区负责一部分事务，事务分区是根据事务Id的hashcode值%50,</p>
<p>计算该事务处于哪个分区，该分区Leader副本所在的broken节点即为这个事务id对应的事务控制器节点</p>
<p>一个broken缓存接收五个request，如果五个request都符合要求（序号正确）则可以落盘，否则要重试</p>
<h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p>可以查看broker信息，每台broker启动后，都会在zookeeper中注册</p>
<p>ids brokerid列表</p>
<p>主节点选举规则，以isr中存活为前提，按照AR中排在前面的优先，ar[1,0,2], isr[1,0,2], 那么leader就会按照1，0，2的顺序轮询</p>
<p>创建一个负载均衡的topic</p>
<p>vim topics-to-move.json</p>
<p>{<br>    “topics”: [<br>        {“topic”: “first”}, {“topic”: “second”}<br>    ]<br>}</p>
<p>节点退役，生成一个退役计划，写入increase- replication-factor.json</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><ol>
<li><p>生产者</p>
<p>100T数据</p>
</li>
<li><p>broker</p>
<ol>
<li>broker 服务器 Hadoop102 103 104</li>
<li>topic 主题 对数据的分类</li>
<li>分区</li>
<li>可靠性   副本</li>
<li>leader follower</li>
<li>生产者和消费者 只针对leader操作</li>
</ol>
</li>
<li><p>消费者</p>
<ol>
<li>消费者和消费者相互独立</li>
<li>消费者组（某个分区，只能由一个消费者消费）</li>
</ol>
</li>
<li><p>zookeeper</p>
<ol>
<li>broker.ids 0 1 2</li>
<li>leader</li>
</ol>
</li>
</ol>
<h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><ol>
<li><p>安装</p>
<ol>
<li>broker.id 必须全局唯一</li>
<li>broker.id log.dirs zk.kafka</li>
<li>启动停止 先停止Kafka，再停zookeeper</li>
<li>脚本<br>#!/bin/bash</li>
</ol>
</li>
<li><p>常用命令行</p>
<ol>
<li>主题Kafka0 topic.sh</li>
<li>生产者 Kafka-console-producer.sh</li>
<li>消费者 kafka-console-consumer.sh</li>
</ol>
</li>
</ol>
<p>3.过程<br>    1. Kafka Producer<br>    2.  send<br>    3.  拦截器<br>    4.  序列化thrim<br>    5.  分区器，32M发送缓存，sender线程发送，<br>        1. 批次到或者时间到就可以发送<br>        2. NIO selector 打通，网络IO到指定集群的broker，分区副本之间同步</p>
<ol start="3">
<li><p>生产者</p>
<ol>
<li>原理</li>
<li>异步发送API<ol>
<li>配置<ol>
<li>连接 bootstrap- server</li>
<li>key value序列化</li>
</ol>
</li>
<li>创建生产者 KafkaProducer&lt;String, String&gt;()</li>
<li>发送数据 send() send( , new Callback)</li>
<li>关闭资源</li>
</ol>
</li>
<li>同步发送 send() send( ,new Callback).get()</li>
<li>分区<ol>
<li>分区的好处<ol>
<li>存储</li>
<li>计算</li>
</ol>
</li>
<li>默认分区规则<ol>
<li>指定分区，按分区走</li>
<li>key key的hashcode值%分区数</li>
<li>没有指定key 没有指定分区 黏性</li>
</ol>
</li>
<li>自定义分区 定义类 实现partition接口</li>
</ol>
</li>
<li>吞吐量提高<ol>
<li>批次大小 16k 32k</li>
<li>linger.ms 0=》5-100ms</li>
<li>压缩</li>
<li>缓存区大小 32m =》 64m</li>
</ol>
</li>
<li>可靠性<ol>
<li>acks=0 会丢失数据 效率最高</li>
<li>acks=1 也可能会丢，leader有应答机制 传输普通日志</li>
<li>acks=-1 完全可靠 + 副本数量大于等于2 + isr大于等于2 =》不会丢失，会有数据重复</li>
</ol>
</li>
<li>数据重复问题<ol>
<li>幂等性<ol>
<li>&lt;pid, 分区号， 序列号&gt; 保证单机单连接 序列号单调递增</li>
<li>事务<ol>
<li>底层基于幂等性</li>
<li>事务协调性 默认用50个分区，分布在各个节点？</li>
<li>事务id，对50取模，找到分区，所在的broker，的事务协调器，就是本次事务的负责人</li>
<li>生产者会跟事务协调器申请一个pid，给到之后向leader发送数据</li>
<li>发送数据之后，发送commit申请，然后根据持久化的结果返回给生产者，生产者再删除数据</li>
<li>五个API<ol>
<li>初始化</li>
<li>启动</li>
<li>消费者offset</li>
<li>提交</li>
<li>终止</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>数据有序<ol>
<li>单分区内有序</li>
<li>多分区有序</li>
</ol>
</li>
<li>乱序<ol>
<li>inflight 设置为1</li>
<li>没有幂等性</li>
<li>有幂等性 对数个请求进行缓存，</li>
</ol>
</li>
</ol>
</li>
<li><p>broker</p>
<ol>
<li><p>zookeeper存储了哪些信息</p>
<ol>
<li>broker.ids</li>
<li>leader</li>
<li>辅助选举 controller</li>
</ol>
</li>
<li><p>工作流程</p>
<ol>
<li>每个节点都有controller，参与主节点的竞争</li>
<li>选择AR节点内的，并且活着的排在前面的作为leader</li>
<li>生产者发送数据给集群的主节点进行读写，leader收到数据之后，follower会主动跟他同步，拉取数据，持久到磁盘。位置在logdir,topic不同的分区的log目录，</li>
<li>log存储消息文件、index、timeIndex。分区也会创建索引，方便查询</li>
<li>消息索引</li>
</ol>
<p>bin/kafka-run-class.sh kafka.tools.DumpLogSegments –files 00000000000000000000.index</p>
<p>最后一行<br>offset:5083  position:1072592768</p>
<ol start="6">
<li>Kafka如何查找指定offset的Message的<ol>
<li>二分查找索引</li>
</ol>
</li>
</ol>
</li>
<li><p>服役和退役</p>
<ol>
<li>准备一台新服务器 Hadoop</li>
<li>对哪个topic主题操作</li>
<li>形成计划</li>
<li>执行计划</li>
<li>验证计划</li>
</ol>
</li>
<li><p>退役</p>
<ol>
<li>要退役的节点不让存储数据</li>
<li>退出节点</li>
</ol>
</li>
</ol>
</li>
<li><p>Kafka副本</p>
<ol>
<li>默认副本1个，生产环境一般默认两个，保证数据可靠性。太多副本增加磁盘存储空间，增加网络上数据传输，降低效率</li>
<li>Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往leader，然后Follower找leader进行同步数据</li>
<li>Kafka分区中的所有副本统称为AR（Assigned Replicas） AR=ISR+OSR<ol>
<li>ISR： 表示和Leader保持同步的Follower集合（即经常保持活跃的可靠的Follower）。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s，Leader发生故障后，就会从ISR选举新的leader。</li>
<li></li>
</ol>
</li>
</ol>
</li>
<li><p>leader选举流程</p>
<ol>
<li>在isr中存活为前提，按照AR中排在前面的优先</li>
</ol>
</li>
<li><p>Follower故障处理细节</p>
<ol>
<li>LEO（long End Offset）每个副本的最后一个offset，LEO其实就是最新的offset+1</li>
<li>HW （High Watermark） 所有副本中最小的 LEO<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332avc7d4j20wq0mu763.jpg"></li>
<li>Follower故障之后，会被临时踢出ISR。这个期间Leader和Follower继续接收数据</li>
<li>待该Follower恢复后，Follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332b1fb9bj215a0m60vq.jpg"></li>
<li>等待Follower的LEO大于等于该 partition的HW，即Follower追上Leader之后，就可以重新加入ISR了。</li>
</ol>
</li>
<li><p>Leader故障处理细节</p>
<ol>
<li>Leader发生故障之后，会从ISR中选出一个新的Leader<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332b6vph5j21440kk40s.jpg"></li>
<li>为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据</li>
<li>注意，只能保证副本之间的数据一致性，不能保证数据不丢失或者不重复<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332bb58y6j214k0dutcm.jpg"></li>
<li>新建一个topic，16个分区，3个副本，1主2从</li>
<li>生产经验，调整分区分布。Kafka默认各个服务器条件一致，实际可以根据服务器的配置与使用情况</li>
<li>正常情况下，Kafka本身会自动把Leader partition均匀分布在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致leader partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写压力过高，其他的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡</li>
<li>可以设置auto.leader.rebalance.enable，默认上true，自动Leader partition平衡<ol>
<li>平衡比例默认是10%，每个broker允许的不平衡的leader的比例。如果每个broker超过了这个值，控制器会处罚leader的平衡</li>
<li>leader.imbalance.check,interval,seconds默认值是300s，检查leader负载是否均衡的间隔时间。</li>
</ol>
</li>
</ol>
</li>
<li><p>文件存储</p>
<ol>
<li>Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应一个log文件，该log文件存储的就是Produce生产的数据。</li>
<li>produce生产的数据会不断追加到该log文件的末端，为防止log文件过大导致数据定位效率低，Kafka采取了分片和索引机制，将每个partition分为多个segment。</li>
<li>每个segment又包括：“index文件、log文件和timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如first-0<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332bgj6qlj214g0l0wi7.jpg"></li>
<li>log的组成，bashoffset lastoffset count baseSequence lastSequence, producerId</li>
</ol>
<p>在log中定位，根据文件名用二分查找</p>
</li>
<li><p>文件清理策略</p>
<ol>
<li>Kafka默认的日志保存时间为7天，可以通过调整如下参与修改保存时间</li>
<li>清除策略又有delete和compact两种<ol>
<li>delect删除 设置有效期</li>
<li>compact 日志压缩，对于相同的key的不同value值，且只保留最后一个版本</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="页缓存-零拷贝"><a href="#页缓存-零拷贝" class="headerlink" title="页缓存 零拷贝"></a>页缓存 零拷贝</h2><ol>
<li>零拷贝：Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据？ 所以不用走应用层，传输效率高<ol>
<li><p>假设不用非零拷贝工作流程</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332bzu4coj21i70u0ten.jpg"></p>
</li>
</ol>
</li>
</ol>
<h2 id="kafka的消息方式"><a href="#kafka的消息方式" class="headerlink" title="kafka的消息方式"></a>kafka的消息方式</h2><ol>
<li>pull拉模式<br>consumer采用从broker中主动拉取数据<br>Kafka采用这种方式</li>
<li>push推模式<br>Kafka没有采用这种方式，因为由broker决定消息发送效率，很难适应所有消费者的速率。如果推送的速度过快，消费者将会来不及消费数据</li>
<li>pull模式不足之处是，如果Kafka没有数据，消费者 kennel会陷入循环中，一直返回数据</li>
<li>一个消费者组消费一个分区。消费到哪了，offset存储在消费者主机内，方便管理，减少与zookeeper之间的通信</li>
<li>消费者组原理<ol>
<li>组成条件<ol>
<li>所有消费者都有一个消费者组ID</li>
<li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费</li>
<li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上一个订阅者<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332c9yx5hj214k0mmdjx.jpg"></li>
<li><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332ceolu7j214s0mygp8.jpg"></li>
</ol>
</li>
<li>消费者组初始化流程<ol>
<li><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332ckohdzj21hr0u0do5.jpg"></li>
<li>一个消费者消费一个分区<br><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h332cpvlysj21h20u0qau.jpg"></li>
</ol>
</li>
</ol>
</li>
<li>生产经验-分区的分配以及再平衡<ol>
<li>一个consumer group有多个consumer组成，一个topic由多个partition组成，现在问题是，到底由哪个consumer来消费哪个partition数据</li>
<li>Kafka分配过程<ol>
<li>每个consumer都发送joinGroup请求</li>
<li>选出一个consumer作为leader</li>
<li>把药消费的topic情况发送leader消费者</li>
<li>leader会负责定消费方案</li>
<li>把消费方案发给coordinator</li>
<li>coordinator就把消费方案下发给各个consumer</li>
<li>每个消费者都会和coordinator保持心跳(默认3s),一旦超过session.timeout.ms=45s,该消费者会被移除，并触发再平衡，或者消费者处理消息的时间过长(max.poll.interval.ms5分钟),也会触发再平衡</li>
</ol>
</li>
</ol>
</li>
<li>有四种主流的分区分配策略<ol>
<li>range是对每个topic而言，对消费者序号进行排序，平均分配。如果对于除不尽的情况，8/3，即会造成资源倾斜，topic多的时候会造成某些节点压力过大。</li>
<li>roundRobin轮询分区策略，<strong>是把所有的partition和所有的consumer</strong>都列出来，然后按照hashcode进行排序，最后通过轮询算法来分配partition给到各个消费者。弥补了range算法的多个topic造成某些节点压力过大的问题。</li>
<li>sticky以及再平衡。尽量均匀分配，再某个节点破坏了之后，会保证原有消费者的指定的分区不改变，破坏节点的分区均匀的分配到其余节点上。</li>
</ol>
</li>
<li>自动提交<ol>
<li>默认开启自动提交，5s提交一次。生产者发送消息，消费者不间断地拉取，而offset由Kafka每5s自动提交到consumer_offset中，可设置提交时间间隔。</li>
<li>虽然自动提交比较简单便利，但不够灵活，开发人员很难把握offset提交的时机。手动提交分为两种，分别是<ol>
<li>commitSync同步提交<ol>
<li>同步提交必须等待offset提交完毕之后，再去消费下一批数据</li>
</ol>
</li>
<li>commitAsync异步提交<ol>
<li>发送完提交offset之后，就可以消费下一批数据了，不需要等待提交完毕的结果</li>
<li><strong>生产环境中通常异步提交的比较多</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = ''; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://example.com/2022/05/20/5%E6%9C%8820%E6%97%A5/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://example.com/2022/05/20/5%E6%9C%8820%E6%97%A5/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a target="_blank" rel="noopener" href="http://baidu.com " style="border-bottom: none;">wzr1005</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
